\documentclass[a4paper,10pt]{article}
%\documentclass[draftcls, onecolumn, 11pt]{IEEEtran}
%\documentclass[journal]{IEEEtran}
 
\usepackage{../mathbf-abbrevs}
\input{../defs.tex}

\usepackage{zref-xr,zref-user}
\zexternaldocument*{../paper}

\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.8}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\usepackage{amsmath,amsfonts,amssymb, amsthm, bm}

%\usepackage[square,comma,numbers,sort&compress]{natbib}

\usepackage{color}
\newcommand{\comment}[1]{\textcolor{red}{#1}}

\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\sinc}{\operatorname{sinc}}
\newcommand{\rect}[1]{\operatorname{rect}\left(#1\right)}

%opening
\title{Fast sparse period estimation: Reviewer responses}
\author{R.~G.~McKilliam, I.~V.~L.~Clarkson and B.~G.~Quinn 
%\thanks{}
}

\renewcommand{\theenumii}{(\alph{enumii})}
\renewcommand{\labelenumii}{\theenumii}

\begin{document}

\maketitle


\section*{Reviewer 1}\label{sec:reviewer-1}

\begin{enumerate}
 
\item\textbf{Comment:}
This paper proposes a new fast method for estimating the period of sparse and noisy
observations of a point process. The new idea is to use the periodogram of quantized
observations that can be computed faster than the standard periodogram by using
a chirp z-transform or a fast Fourier transform. The reviewer is not convinced that
there is enough material deserving publication in the IEEE signal processing letters.
Moreover, there are several important comments that should be addressed before a
possible publication of this letter.
\\
\textbf{Response:}
We agree with the reviewer that the results in this paper are simple.  We do not believe this to be a weakness. Whilst being simple, the results are also novel and useful.  The quantisated periodogram estimator described in this paper is as accurate as the most accurate estimators in the literature (the least squares and periodogram estimators).  At the same time our estimator is substantially faster to compute.  For these reasons, we firmly believe this will become the estimator of choice for periodic point processes.  It enables highly accurate period estimation for extremely large data sets in reasonable time. This was not possible with previous estimators that require a number of operations growing quadratically with data size. %We have provided all the simulation code as supplementary material.  This will enable simple implementation for future research.

\item\textbf{Comment:}
The main reviewer concern is about the choice of the quantization parameter
$q$ that should be explained more carefully. It is not sufficient to display two sets
of curves obtained for two different values of $q$ and to choose the best one without
explanations. For instance, it is not clear whether the value of $q$ chosen in this paper
will be appropriate for other noise distributions or for other ways of generating the
integers $s_n$. This point should be addressed carefully before a possible resubmission
of the paper. The other reviewer comments are summarized below.
\\
\textbf{Response:}
We anticipate that developing a rigorous theoretical method for choosing $q$ will be extremely complicated.  The properties of many optimisation proceedures, such as the Newton-Raphson method, are reasonably well understood for the purpose of maximising fixed known functions. However, very few theorectical statistical analyses for these proceedures exist when the functions to be maximised are themselves random variables, i.e., when noise is involved.  Add to this the existence of quantisation (itself typically very tricky to analyse) and it appears that a theorectical analysis of this estimator will be extremely difficult.

These theoretical difficulties do not negate the immediate practical applicability of our estimator.  We believe it would be unwise to halt dissemination of these practical results simply because a difficult theoretical problem has not yet been solved.  We agree with the reviewer that the simulations presented are limited. This is due to the 4 page limit required IEEE Signal Processing Letters (a 5th page containing only references is also allowed).  In the paper we use our simulations to motivate the choice $q = 5 f_{\text{max}}$ for the quantisation parameter.  We have found this choice works well under an array of different noise distributions and methods for generating the intergers $s_1,\dots,s_N$  For example, Figures~\ref{plot:poisson} and~\ref{plot:geomuniform} in this document show simulations similar to those in the paper, but with the following modifications:

\begin{enumerate}
\item In Figure~\ref{plot:poisson} the noise is Gaussian distributed, $N=200$, and the integers are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically \emph{Poisson distributed} with mean $\mu = 1$ in the plot on the left and mean $\mu=10$ in the plot on the right.  Five hundred Monte-Carlo trials are used for each value of $\sigma^2$.
\item In Figure~\ref{plot:geomuniform} the noise if \emph{uniformly distributed}, $N=200$, and the integers are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically Geometrically distributed with mean $\mu = 1$ in the plot on the left and mean $\mu=10$ in the plot on the right.  Five hundred Monte-Carlo trials are used for each value of $\sigma^2$.   The least squares estimator is the most accurate in this simulation. This is predicted by the asymptotic theory~\cite{Quinn_sparse_noisy_SSP_2012,Quinn20013asilomar_period_est}.
\end{enumerate}

Observe that, in both simulations, the choice $q=5 f_{\text{max}}$ provide good accuracy. With this choice, the accuracy of the quantised periodogram estimator is similar to the original periodgram estimator computed without quantisation and FFT.  %That the choice $q=5 f_{\text{max}}$ works in a wide range of scenarios should not come as a  


\begin{figure}[p] 
  \centering 
  \begin{tikzpicture} 
    \selectcolormodel{gray} 
    \begin{axis}[name=plot1,font=\footnotesize,xmode=log,ymax=4e-1,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.24)}},xlabel style={at={(0.5,0.07)}}, legend style={at={(1.1,1.02)}, anchor=south,legend columns=7, cells={anchor=west,/tikz/every even column/.append style={column sep=0.2cm}}}]
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200poisson1}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200poisson1};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q1.5poisson1};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN200q5.0poisson1};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN200poisson1};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.2}] table {code/data/NormalisedSamplingLLSN200poisson1}; 
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN200poisson1};
      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN200poisson1};
     \legend{Periodogram theory, LS theory, $q=\tfrac{3}{2}f_{\text{max}}$, $q=5 f_{\text{max}}$, Periodogram, LS, SLS2-new}
     %\node[rotate=17,font=\footnotesize] at (axis cs:6e-4,1e-7) {$N=200$};
   \end{axis} 
 \begin{axis}[name=plot2,at={(10.5,0)},ymax=4e-1,font=\footnotesize,xmode=log,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.23)}},xlabel style={at={(0.5,0.07)}}]
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200poisson10}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200poisson10};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q1.5poisson10};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN200q5.0poisson10};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1.1}] table {code/data/PeriodogramN200poisson10};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.3}] table {code/data/NormalisedSamplingLLSN200poisson10}; 
  %     \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN200poisson10};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN200poisson10};
     %\node[rotate=16,font=\footnotesize] at (axis cs:7e-4,1.5e-14) {$N=200$}; 
   \end{axis} 
  \end{tikzpicture}  
  \caption{Mean square period error versus noise variance $\sigma^2$ with Gaussain noise and $N=200$ observations.  The integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically Poisson distributed with mean $\mu = 1$ in the plot on the left and mean $\mu=10$.}\label{plot:poisson}
\end{figure} 


\begin{figure}[p]  
  \centering
  \begin{tikzpicture}  
    \selectcolormodel{gray} 
    \begin{axis}[name=plot1,font=\footnotesize,xmode=log,ymax=4e-1,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.24)}},xlabel style={at={(0.5,0.07)}}, legend style={at={(1.1,1.02)}, anchor=south,legend columns=7, cells={anchor=west,/tikz/every even column/.append style={column sep=0.2cm}}}]
\addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200uniformgeom1}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200uniformgeom1};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q1.5uniformgeom1};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN200q5.0uniformgeom1};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN200uniformgeom1};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.2}] table {code/data/NormalisedSamplingLLSN200uniformgeom1}; 
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN200uniformgeom1};
      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN200uniformgeom1};
     \legend{Periodogram theory, LS theory, $q=\tfrac{3}{2}f_{\text{max}}$, $q=5 f_{\text{max}}$, Periodogram, LS, SLS2-new}
     %\node[rotate=17,font=\footnotesize] at (axis cs:6e-4,1e-7) {$N=200$};
   \end{axis}   \begin{axis}[name=plot2,at={(4.7,0)},ymax=4e-1,font=\footnotesize,xmode=log,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.23)}},xlabel style={at={(0.5,0.07)}}]
\addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200uniformgeom10}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200uniformgeom10};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q1.5uniformgeom10};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN200q5.0uniformgeom10};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1.1}] table {code/data/PeriodogramN200uniformgeom10};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.3}] table {code/data/NormalisedSamplingLLSN200uniformgeom10}; 
  %     \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN200uniformgeom10};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN200uniformgeom10};
     %\node[rotate=16,font=\footnotesize] at (axis cs:7e-4,1.5e-14) {$N=200$}; 
   \end{axis} 
  \end{tikzpicture}  
  \caption{Mean square period error versus noise variance $\sigma^2$ with uniform noise and $N=200$ observations.  The integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed with mean $\mu = 1$ in the plot on the left and mean $\mu=10$.  The least squares estimator is the most accurate in this simulation. This is predicted by the asymptotic theory~\cite{Quinn_sparse_noisy_SSP_2012,Quinn20013asilomar_period_est}.}\label{plot:geomuniform}
\end{figure}


\item\textbf{Comment:}
p. 3, the authors mention “Sadler and Casey [24] \dots However, their estimator
requires far larger transforms and produces less accurate results than the estimator
described here (see Section VI)". Unfortunately, there is nothing in
Section VI (which is the conclusion) supporting this claim. The authors should
compare their results in term of accuracy and of computational complexity to
the results of [24]. Including the Cramer-Rao bounds for the estimation of $T_0$
(as in [24]) would also be appreciated.
\\
\textbf{Response:}

We response to each of the reviewers comments in turn.

\begin{enumerate}

\item \textbf{Unfortunately, there is nothing in
Section VI (which is the conclusion) supporting this claim.}

Section VI in the paper~\cite{726812} entitled ``On periodic pulse interval analysis with outliers and missing observations'' is not the conclusion.  It is the section entitled ``Numerical Results''.  In Figures 1 to 4 in~\cite{726812} the periogram estimator implemented by Casey and Sadler is seen to be inferior to their MEA estimator.  Casey and Sadler do use an FFT to compute the periodgram, but fail to implement an optimisation proceedure. % We used the Newton-Raphson proceedure in the old manuscript, but have used Brent's method~\cite{Brent_opt_no_derivs_1973} in the new manuscript as dicussed in our response to comment~\ref{com:rev1:nr} below.  
Casey and Sadler arrive at the conclusion that very large FFTs are required and that the periodgram estimator is not particularly accurate.  In the conclusion of~\cite{726812} it is stated that:

``Comparisons with the periodogram show the limitations of periodogram performance.''

Our paper clearly shows that such limitation do not exist.  The periodgram estimator, computed by quantization and FFT and combined with an appropriate optimisation proceedure, is both compuationally efficient and highly accurate.  For moderately large $N$ this is the most computationally efficient proceedure currently available for this problem.  Simultaneously, it is as accurate at the most accurate estimators available, namely the least squares estimator, and the periodgram estimator computed directly without FFT.

\item \textbf{ The authors should
compare their results in term of accuracy and of computational complexity to
the results of [24].}

We have not implemented and do not present simulations results with any of the MEA estimators from the papers by Casey and Sadler~\cite{536682,726812}.  The MEA estimators were supersceeded by the Separable Line Search (SLS) estimators of Sidiropoulos, Swami and Sadler~\cite{Sidiropoulos2005} in 2005.  Comparison between the MEA estimators and the SLS estimators are presented in~\cite{Sidiropoulos2005} where the superiority of the SLS estimators is shown.  An enhanced SLS estimator (SLS2-new) was developed in~\cite{Clarkson2007} and this is the estimator we show simulations results for\footnote{One of the SLS estimators (SLS2-all) has excellent statistical accuracy.  It is almost as accurate as the least squares and periodogram estimators as can be see in the simulations in~\cite{Clarkson2007} and~\cite{McKilliam2007}.  However, it is extremely computationally complex, requiring atleast $O(N^3)$ operations to compute.  We cannot present simulation results for this estimator when $N=1200$ for example.  This estimator is discussed and compared in~\cite{Sidiropoulos2005} and also~\cite{Clarkson2007,McKilliam2007}.}.  Even this enhanced SLS estimator performs poorly when compared to the least squares and periodogram estimators.  The MEA estimators are no longer state-of-the-art for this problem.

\item \textbf{Including the Cramer-Rao bounds for the estimation of $T_0$
(as in [24]) would also be appreciated.}

In the simulations we regenerate the integers $s_1,\dots,s_N$ on each Monte-Carlo trial.  To make this clear in the paper the following sentence is included:

``For each Monte-Carlo trial the integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed starting from zero with means $\mu=1$ and $10$.''
 
To the authors knowledge, a Cramer-Rao bound is not known in this case.   The \emph{clairvoyant} Cramer-Rao bound from~\cite{Sidiropoulos2005} (also \cite{726812,Clarkson2007}) supposes a single fixed realisation for $s_1,\dots,s_N$.  This bound is therefore not valid for the simulations we present in Figure~\zref{plot:multipleN} in Section~\zref{sec:simulations} of the paper.  

In Figure~\ref{plot:crb} in this document we perform a simulation with fixed integers $s_1,\dots,s_N$. The integers are generated once such $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed.  This single fixed sequence is used for all 500 Monte-Carlo trials.  Observe that for small noise variance the \emph{clairvoyant} Cramer-Rao bound is similar to the asymptotic variance of the least squares and periodogram estimators predicted in~\cite{Quinn_sparse_noisy_SSP_2012,Quinn20013asilomar_period_est}.  As the noise variance increases the \emph{clairvoyant} Cramer-Rao bound and the predicted asymptotic variances diverge.  As expected, the behaviour of the estimators themselves follows the asymptotic theory, rather than the \emph{clairvoyant} Cramer-Rao bound.

Observe that in the left hand plot of Figure~\ref{plot:crb} the quantised periodogram estimator with coarse quantisation $q = 1.5 f_{\text{max}}$ (triangles) actually performs well for sufficently small noise variance.  It appears that the fixed integers $s_1,\dots,s_N$ generated in this simulation favour the quantised periodogram estimator.  This is one motivation for performing simulations with integers $s_1,\dots,s_N$ generated randomly for each Monte-Carlo trial, rather than choosing a single fixed set of integers.  It avoids the scenario where a particular favourable set $s_1,\dots,s_N$ is chosen by chance.


%We prefer to show to plot the MSE of the estimatorsThe least squares estimator is the maximum likelihood estimator, and so, the dashed curve serves a similar type of purpose as the CRB often does in these types of simulations.  Namely, to indicate whether an estimator is performing similarly to what might be considered `optimal', i.e. close the what might theoretically be expected from the maximum likelihood estimator.

\end{enumerate}

\item\textbf{Comment:}\label{com:rev1:nr}
p. 7, the authors indicate that they have used the Newton-Raphson (NR)
method. More details should be provided here. For instance, what is the exact
NR scheme used in this paper (there are several options)? How have the
authors selected the total number of iterations? Is the quantized periodogram
just used to initialize a Newton-Raphson procedure? Do the MSEs displayed
in Fig. 3 correspond to the estimator obtained after applying the NR algorithm?
Also, do the results displayed in Fig. 2 correspond to the total time
required to compute the estimator (including the NR procedure) or just to the
initialization of the NR procedure?
\\
\textbf{Response:}
We repond to each of the questions of the reviewer in turn:

\begin{enumerate}
\item \textbf{For instance, what is the exact NR scheme used in this paper (there are several options)?}  
In the new version of the paper the following paragraph has been included in Section~\zref{sec:comp-compl}:

``Given the approximate maximiser $\widetilde{f}^\prime$ we apply the Newton-Raphson method to find a nearby stationary point of the periodogram $I_y$.  This proceeds by the iteration
\[
f_{n+1} = f_{n} - \frac{I_y^\prime(f_n)}{I_y^{\prime\prime}(f_n)}, \qquad f_{1} = \widetilde{f}^\prime
\]
where $I_y^\prime$ and $I_y^{\prime\prime}$ are the first and second derivative of $I_y$. This procedure converges to the maximiser $\hat{f}$ of $I_y$ provided that $\widetilde{f}^\prime$ is sufficiently close to $\hat{f}$.  In our implementation iterations are performed until $\sabs{f_{n+1}-f_n} < 10^{-10}$.  The number of iterations depends upon the distance $D$, but not on $N$.  Each iteration requires $O(N)$ operations and so the total number of operations required by the Newton-Raphson procedure has order $O(N)$.  In practice we find that the computational cost of the Newton-Raphson procedure negligible when compared to the cost of the chirp-z or fast Fourier transforms.''

% The Netwon-Raphson method that was used proceeds by the iteration
% \[
% x_{n+1} = x_n - \frac{f^\prime(x_{n})}{f^{\prime\prime}(x_n)}
% \]
% to find a stationary point of the function $f$ where $f^\prime$ and $f^{\prime\prime}$ are the first and second derivatives of $f$.  To avoid the potential ambguity regarding the definition of the Newton-Raphson method we have, in the new manuscipt, replaced the Newton-Raphson method with the optimisation proceedure due to Brent~\cite[Ch.~5]{Brent_opt_no_derivs_1973}.  This optimiation method is likely to be more familiar with readers because it is used internally by the \texttt{fminbnd} function in the popular MATLAB environment. 

% BLERG add some text to the paper.

\item \textbf{How have the authors selected the total number of iterations?} 
As described in the above paragraph ``iterations are performed until $\sabs{f_{n+1}-f_n} < 10^{-10}$.''

% In our implementation iterations are performed until the absolute difference between consequentive iterations is less than $10^{-7}$.

% BLERG: Something like the following should be added:

% ``Brent's method is iterative.  During the method a number of evaluations of the periodogram $I_y$ are made.  The number of calls depends on the grid width $D$, but not on $N$.  Each call requires $O(N)$ operations, and so, the total number of operations required by Brent's method is $O(N)$. In practice we find that that computational cost of Brent's method is far smaller than the cost of either that FFT or chirp-z transform.''

\item \textbf{Is the quantized periodogram just used to initialize a Newton-Raphson procedure?}
Yes.  As described in the paper BLERG

\item \textbf{Do the MSEs displayed in Fig. 3 correspond to the estimator obtained after applying the NR algorithm?}
Yes.

\item \textbf{Also, do the results displayed in Fig. 2 correspond to the total time
required to compute the estimator (including the NR procedure) or just to the
initialization of the NR procedure?}
Yes. The estimators run in the benchmarks in Figure~\zref{plot:benchmark} are exactly the same as those in the simulations in Figure~\zref{plot:multipleN}.  For the periodogram and quantised peridogram estimators this includes the Newton-Raphson proceedure.

\end{enumerate}



\item\textbf{Comment:}
p. 5, in the definition of $v_m$, $b_{m+\ell_1}$ should be replaced by $b_{m+\ell_{\text{min}}}$.
\\
\textbf{Response:}
Thankyou for spotting this error.  A similar error was fixed in equation for $I_z$ directly above this. 


\item\textbf{Comment:}
p. 6, ``each of length $L+K-1$'' might be replaced by ``each of length $M = L + K - 1$"
\\
\textbf{Response:}
Respectfully, we have not done this.  The parameter $M$ is reserved for the length of the FFT used for the single Fourier transform method.  We feel it is confusing if $M$ is also used for the length of the transforms required by the chirp-z transform.


\item\textbf{Comment:}
p. 8, $n = 2,\dots,N$ should be $n = 1, \dots, N - 1$
\\
\textbf{Response:}
This error has be fixed.  The same error in the caption of Figure~\zref{plot:multipleN} has been fixed.


\item\textbf{Comment:}
p. 8, it is not completely clear to identify the curves associated with $N = 30$ and $N = 1200$. Can the authors display 4 curves associated with $\mu= 1$, $\mu = 10$, $N = 30$ and $N = 1200$?
\\
\textbf{Response:}
The formatting of Figure~\zref{plot:multipleN} has been improved.  Each simulation for $N=30,1200$ and $\mu=1,10$ is now presented in its own plot.

\item\textbf{Comment:}
Typos: p. 2, ``anomolies'' should be ``anomalies'', p. 7, ``quanitised'' should be
``quantized''.
\\
\textbf{Response:}
Done.


\item\textbf{Comment:} 
Is it necessary to include 11 self citations in this letter? Removing some of
these references would allow to save some space, which could be used to better
explain some points mentioned above.
\\
\textbf{Response:}
IEEE Signal Processing Letters allows a 5th page that can contain only references.  Therefore, we cannot save space by removing references.   We have removed reference [29] from the original manuscript because the material in that paper is also covered in [27].  We have also removed references [33] and [34] from the original manuscript. We feel that the all 35 references in the new version of the paper are highly relevant. The paper would be weakened without them.

\end{enumerate}



\begin{figure}[tp]  
  \centering
  \begin{tikzpicture}  
    \selectcolormodel{gray}
    \begin{axis}[name=plot1,font=\footnotesize,xmode=log,ymax=4e-1,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.24)}},xlabel style={at={(0.5,0.07)}}, legend style={at={(1.1,1.02)}, anchor=south,legend columns=8, cells={anchor=west,/tikz/every even column/.append style={column sep=0.2cm}}}]
\addplot[mark=none,color=black] table {code/data/PeriodogramCLTN500fixed1}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN500fixed1};
      \addplot[mark=none,color=black,dotted] table {code/data/CRBN500fixed1};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN500q1.5fixed1};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN500q5.0fixed1};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN500fixed1};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.2}] table {code/data/NormalisedSamplingLLSN500fixed1}; 
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN500fixed1};
      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN500fixed1};
     \legend{Periodogram theory, LS theory, CRB, $q=\tfrac{3}{2}f_{\text{max}}$, $q=5 f_{\text{max}}$, Periodogram, LS, SLS2-new}
     %\node[rotate=17,font=\footnotesize] at (axis cs:6e-4,1e-7) {$N=200$};
   \end{axis}   \begin{axis}[name=plot2,at={(9.5,0)},ymax=4e-1,font=\footnotesize,xmode=log,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.06,0.23)}},xlabel style={at={(0.5,0.07)}}]
\addplot[mark=none,color=black] table {code/data/PeriodogramCLTN500fixed10}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN500fixed10};
      \addplot[mark=none,color=black,dotted] table {code/data/CRBN500fixed10};
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN500q1.5fixed10};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN500q5.0fixed10};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1.1}] table {code/data/PeriodogramN500fixed10};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.3}] table {code/data/NormalisedSamplingLLSN500fixed10}; 
  %     \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN500fixed10};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN500fixed10};
     %\node[rotate=16,font=\footnotesize] at (axis cs:7e-4,1.5e-14) {$N=200$}; 
   \end{axis} 
  \end{tikzpicture}
  \caption{Mean square period error versus noise variance $\sigma^2$ with Gaussian noise and $N=500$ observations.  A singled fixed set of integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed with mean $\mu = 1$ in the plot on the left and mean $\mu=10$.  This single fixed sequence is used for all of the $500$ Monte-Carlo trials.  In this case the \emph{clairvoyant} Cramer-Rao bound from~\cite{Sidiropoulos2005} (also in \cite{726812,Clarkson2007}) exists and is displayed by the dotted line.  In this simulation the \emph{clairvoyant} Cramer-Rao bound is equal to the variance of the maximum likelihood (i.e. least squares) estimator in the case that the integers $s_1,\dots,s_N$ are known.}\label{plot:crb}
\end{figure} 


\section*{Reviewer 2}


\begin{enumerate}

\item\textbf{Comment:}
 The identifiability claim at the beginning of sec. II is not obvious and a reference is mandatory. Indeed, referring to eq. (2), let us assume that $s_n = 2 i_n$ where $i_n$ are all non-negative integer. In this case the point process is periodic with period $2 T_0$. This referee does not believe that maximizing the periodogram over $(f_{\text{min}},f_{\text{max}})$ will identify the true frequency (or period). LS methods might have the capabilities to identify the period, but, in any case the claim of idenitifiability needs to be further supported.
\\
\textbf{Response:} The same identifiability requirements are commonly imposed in the literature, see for example, Sidiropoulos~\cite[eq. (2)]{Sidiropoulos2005}.  Suppose that $T_{\text{max}} \geq 2T_{\text{min}}$ and that the true period $T_0$ happened to be contained in the nonempty interval $(2T_{\text{min}}, T_0)$.  Put $T^\prime = T_0/2 \in (T_{\text{min}}, T_{\text{max}})$ and observe that
\[
y_n = T_0 s_n + \theta_0 + w_n = 2 T^\prime s_n + \theta_0 + w_n = T^\prime r_n + \theta_0 + w_n 
\]
where $r_n = 2 s_n \in \ints$.  Since the integers are not known both $T_0$ and $T^\prime$ would describe the observations equally well.  This problem is averted only if we suppose that $T_0 \in (T_{\text{min}}, T_{\text{max}})$ and that  $T_{\text{max}} < 2T_{\text{min}}$.

%Perhaps it is possible to increase the range of identifiability if further assumptions are made regarding the integers $s_1,\dots,s_N$.  We don't consider such propsitions in this paper.

% To see this another way, define least squares objective function $LS : \reals \times \reals \times \ints^N \mapsto \reals$ as
% \[
% LS(T, \theta, z_1,\dots,z_N) = \sum_{n=1}^N (y_n - T z_n - \theta)^2.
% \]
% In the case that the noise variables $w_1,\dots,w_n$ are i.i.d. and normally distributed the minimiser of this objective function with respect to $T$ is the maximum likelihood estimator.  That is,
% \[
% \hat{T} = \arg\min_{T \in (T_{\text{min}}, T_{\text{max}})} \min_{\theta \in \reals} \min_{z_1,\dots,z_N \in \ints} LS(T, \theta, z_1,\dots,z_N)
% \]
% is the maximum likelihood period estimator.

We have included reference~\cite{Sidiropoulos2005} and simplified the text at the start of Section~\zref{sec:peri-estim} to read:

``To ensure identifiability it is necessary to assume, as in~\cite{Sidiropoulos2005}, that $T_0$ lies in some interval $(T_{\text{min}}, T_{\text{max}})$ where $T_{\text{max}} < 2T_{\text{min}}$.''

\item\textbf{Comment:}
Is the equality in the second (un-numbered) equation of page 2 correct?
\\
\textbf{Response:}
Yes.  The terms inside the sum on the left and right are conjugates of one another.  That is,
\[
\sum_{n=1}^N e^{ 2\pi j f y_n} = \sum_{n=1}^N (e^{-2\pi j f y_n})^* = \left( \sum_{n=1}^N e^{ -2\pi j f y_n} \right)^*
\]
where $^*$ denotes the complex conjugate.  So,
\[
I_y(f) = \babs{ \sum_{n=1}^N e^{ 2\pi j f y_n} }^2 = \babs{ \sum_{n=1}^N e^{ -2\pi j f y_n} }^2.
\]

\item\textbf{Comment:}
Newton-Rapson iteration to further improve the frequency estimation is advocated in Sec. II. Can a reference supporting this statement be added?
\\
\textbf{Response:}
Please see our response to comment~\ref{com:rev1:nr} of reviewer 1.

\item\textbf{Comment:}
Referring to Fig. 3, in case $N=30$, the novel method incurs in a significant loss of performance with respect to classical LS and periodogram for low-signal-to-noise ratios. In this scenario (low $N$ and low signal-to-noise-ration) relevant for real applications?
\\
\textbf{Response:}
The quantised periodgram estimator does not suffer a significant performance loss with respect to the classical LS and periodogram estimators in any scenario we have found.  Observe in Figure 3 that the solid dots ($q=5 f_{\text{max}}$) the crosses (LS), the circles (periodogram) are all close for $N=30,1200$ and $\mu=1,10$.  Be aware that the solid lines indicates the asymptotic theory ($N\to\infty$)~\cite{Quinn_sparse_noisy_SSP_2012,Quinn20013asilomar_period_est} for the periodogram and LS estimators and not the measured accuracy for finite $N$.  As $N\to\infty$, the MSE of the periogram and LS estimators will converge to the solid and dashed curves.

\end{enumerate}



{\small
\input{../paper.bbl}
}

\end{document}





















