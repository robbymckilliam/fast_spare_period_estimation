%\documentclass[a4paper,10pt]{article}
%\documentclass[draftcls, onecolumn, 11pt]{IEEEtran}
\documentclass[10pt,twocolumn,twoside]{IEEEtran}
%\documentclass[journal]{IEEEtran}
 
\usepackage{mathbf-abbrevs}
\input{defs}

\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.8}
\usetikzlibrary{pgfplots.groupplots}

%\usepackage{xr}
%\externaldocument{paper2}

\usepackage{amsmath,amsfonts,amssymb, amsthm, bm}

\usepackage[square,comma,numbers,sort&compress]{natbib}

\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\sinc}{\operatorname{sinc}}
\newcommand{\rect}[1]{\operatorname{rect}\left(#1\right)}

%opening
\title{Fast sparse period estimation}
\author{R.~G.~McKilliam, I.~V.~L.~Clarkson and B.~G.~Quinn    
\thanks{
R.~G.~McKilliam is with the Institute for Telecommunications Research, The University of South Australia, SA, 5095.  I.~V.~L.~Clarkson is with the School of Information Technology \& Electrical Engineering, The University of Queensland, QLD., 4072, Australia.  B.~G.~Quinn is with the Department of Statistics, Macquarie University, Sydney, NSW, 2109, Australia.
}}

\begin{document}

\maketitle

\begin{abstract}

The problem of estimating the period of a point process from observations that are both sparse and noisy is considered.  By sparse it is meant that only a potentially small unknown subset of the process is observed.  By noisy it is meant that the subset that is observed, is observed with some error, or noise.  Existing accurate algorithms for estimating the period require $O(N^2)$ operations where $N$ is the number of observations.  By quantizing the observations we produce an estimator that requires only $O(N\log N)$ operations by use of the chirp z-transform or the fast Fourier transform.  The quantization has the adverse effect of decreasing the accuracy of the estimator.  This is investigated by Monte-Carlo simulation.  The simulations indicate that significant computational savings are possible with negligible loss in statistical accuracy.

\end{abstract} 
\begin{IEEEkeywords}
Period estimation, fast Fourier transform
\end{IEEEkeywords}

\section{Introduction}

Consider the periodic sequence of real numbers
\begin{equation}\label{eq:periodicprocess}
T_0 k + \theta_0, \qquad k \in \ints
\end{equation}
with period $T_0$ and phase $\theta_0$.  For example, the sequence might represent times at which the beat occurs in a musical score.  A problem of interest is to estimate $T_0$ and $\theta_0$ from $N$ observations $y_1,\dots,y_N$ of the form
\begin{equation} \label{eq:sigmodel}
y_n = T_0 s_n + \theta_0 + w_n, \qquad n = 1,\dots,N
\end{equation}
where $w_1,\dots,w_N$ represent noise and $s_1,\dots,s_N$ are unknown integers representing the subset of the periodic sequence that is observed.  The $y_1, \dots, y_N$ are \emph{sparse}, owing to the unknown integers $s_1,\dots,s_N$, and \emph{noisy}, owing to $w_1,\dots,w_N$, observations of the sequence~\eqref{eq:periodicprocess}.  For example, $y_1,\dots,y_N$ might represent times at which a bass drum hit is observed.  The drum hits might not occur at every beat and might occur off beat on some occasions.  Our aim in this case would be to estimate the beat of the music from the times of the drum hits.  The model is depicted in Figure~\ref{fig_stat_model}. %It is clear that any estimator of $T_0$ and $\theta_0$ must, either explicitly or implicitly, also produce and estimate of the unknow integers $s_1,\dots,s_N$ describing the subset of the periods that are observed.  

{
\def\vertgap{2}
\def\ph{0.4}
\def\T{1.1}
\newcommand{\raxis}{\draw[->] (-0.25,0) -- (8,0) node[above] {$\reals$}; \draw (0,-0.06)-- node[below] {$0$} (0,0.06) }
\newcommand{\pulse}[1]{ \draw[->,>=latex] (#1,0) -- (#1,1) }
\newcommand{\pulsewithnode}[2]{ \draw[->,>=latex] (#1,0) -- node[right] {#2} (#1,1) }
\begin{figure}[t]
	\centering
\begin{tikzpicture}[font=\small]
    %\draw[very thin,color=gray] (-0.1,-1.1) grid (3.9,3.9);
\begin{scope}
    \raxis;
    \foreach \k in {0,1,...,6} { \k, \pulse{\T*\k+\ph}; }
    \draw[<->] (\T*2+\ph,1.2) -- node[above] {$T_0$} (\T*3+\ph,1.2) ;
    \draw[<->] (0.0,1.2) -- node[above] {$\theta_0$} (\ph,1.2) ; 
%    \draw[->] (-0.25,-2*\vertgap) -- (8,-2*\vertgap) node[above] {$\reals$};
\end{scope}
\begin{scope}[yshift=-\vertgap cm]
  \raxis;
  \node[below] at (\T*1+\ph-0.3,0) {$y_1$}; \pulsewithnode{\T*1+\ph-0.3}{$s_1=1$}; \draw[->] (\T*1+\ph,1.2) -- node[above] {$w_1$} (\T*1+\ph-0.3,1.2) ; 
  \node[below] at (\T*3+\ph+0.5,0) {$y_2$}; \pulsewithnode{\T*3+\ph+0.5}{$s_2=3$}; \draw[->] (\T*3+\ph,1.2) -- node[above] {$w_2$} (\T*3+\ph+0.5,1.2) ;
  \node[below] at (\T*6+\ph-0.4,0) {$y_3$}; \pulsewithnode{\T*6+\ph-0.4}{$s_3=6$};\draw[->] (\T*6+\ph,1.2) -- node[above] {$w_3$} (\T*6+\ph-0.4,1.2) ;
\end{scope}
\end{tikzpicture} 
%		\includegraphics{figs/figures-1.mps}
		\caption{Sparse noisy observations of a periodic sequence.  The original sequence~\eqref{eq:periodicprocess} is shown on the top and sparse noisy observations according to~\eqref{eq:sigmodel} are shown on the bottom.  In this example the observed subset is represented by integers $s_1=1$, $s_2=3$ and $s_3=6$.}
		\label{fig_stat_model}
\end{figure}
}

The problem of estimating $T_0$ is called the \emph{sparse, noisy period estimation problem}~\cite{Clarkson2007,McKilliam2007}.  Solutions have applications to synchronisation for telecommunications devices~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings,Sidiropoulos2005,5621928}, estimation of the pulse repetition interval in electronic support~\cite{EltonGray_puilse_train_rader_1994,Gray_more_pri_1994,Clarkson_thesis,clarkson_estimate_period_pulse_train_1996,Hauochan_pri_2012}, and beat and tempo estimation in music~\cite{dixon_beat_extraction_2001}.  The problem is related to spike interval estimation in neurology~\cite{Arnett_neuro_pri_1976,Brillinger_spike_trains_1988,Rossoni200630} and a similar model has been proposed for the detection of anomalies, such as denial-of-service attacks, in internet traffic~\cite{He_detecting_periodic_patterns_in_internet_2006,5585849,5947313}.  The problem is also connected with classical problems in number theory such as Diophantine approximation, lattice reduction, and the study of prime numbers~\cite{Cassels_geom_numbers_1997,490557,Clarkson_thesis,Lenstra1982,Wubben_2011,536682,726812,CaseySadler_primes_2013}.
 
Least squares estimation of period has been studied in~\cite{Clarkson2007,McKilliam2007,Quinn_sparse_noisy_SSP_2012}.  The least squares estimator can be closely approximated using $O(N^2)$ operations using special purpose algorithms~\cite{McKilliam2009CoxeterLattices,McKilliam2008}.  The least squares estimator is also the maximum likelihood estimator in the case that the noise variables $w_1,\dots,w_N$ are independent and identically normally distributed.  An alternative estimator, called the~\emph{periodogram estimator}, was studied by Fogel and Gavish~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings} and involves the maximisation of Bartlett's periodogram for point processes~\cite{Bartlest_periodgram_point_process_1963}.  The statistical properties of the periodogram estimator were recently studied by Quinn~et.~al.~\cite{Quinn20013asilomar_period_est} who show the estimator to be strongly consistent and asymptotically normal under mild conditions on the noise $w_1,\dots,w_N$ and integers $s_1,\dots,s_N$.  The fastest existing algorithms can closely approximate the periodogram estimator in $O(N^2)$ operations.  We describe the periodogram estimator in Section~\ref{sec:peri-estim}.

In Section~\ref{sec:quant-peri} we show that, by quantizing the observations $y_1,\dots,y_N$, an approximation to the periodogram estimator can be computed using only $O(N\log N)$ operations.  This is facilitated by either the chirp z-transform~\cite{Rabiner1969} or the fast Fourier transform.  The quantization has the adverse affect of decreasing the accuracy of the estimator.  The estimator is accurate if a sufficiently fine quantizer is chosen, but this requires a larger transform.  The trade off between quantization level, accuracy, and computational complexity is investigated by computer simulation in Section~\ref{sec:simulations}.  The simulations indicate that significant computational savings are possible with negligible loss in accuracy.  Sadler and Casey~\cite{726812} have previously suggested use of the fast Fourier transform for period estimation.  However, their estimator requires larger transforms and produces less accurate results than the estimator described here (see Sec.~VI and Fig. 1-4 in~\cite{726812}).  Our estimator has accuracy similar to the least squares estimator, i.e., similar to the maximum likelihood estimator if the noise $w_1,\dots,w_N$ is assumed independent and identically normally distributed.
 
\section{The periodogram estimator}\label{sec:peri-estim}

%Before describing the periodogram estimator we state some required assumptions.  
%Observe that
%\[
%y_n = T_0 s_n + \theta_0 + w_n = \frac{T_0}{2} r_n + \theta_0 + w_n
%\]
%where $r_n = 2s_n \in \ints$.  
To ensure identifiability it is necessary to assume, as in~\cite{Sidiropoulos2005}, that $T_0$ lies in some interval $(T_{\text{min}}, T_{\text{max}})$ where $T_{\text{max}} < 2T_{\text{min}}$.%  We also assume that $y_1,\dots,y_N$ are in ascending order.  The periodogram estimator is unchanged by a permutation observations, and so, this assumption can be made without loss of generality because it amounts only to sorting the observations if required.
Fogel and Gavish~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings} proposed the estimator $\hat{T} = 1/\hat{f}$ where $\hat{f}$ is the maximiser of the~\emph{periodogram}
\[
I_y(f) = \babs{ \sum_{n=1}^N e^{ 2\pi j f y_n} }^2 = \babs{ \sum_{n=1}^N e^{ -2\pi j f y_n} }^2 
\]
over the interval $(f_{\text{min}}, f_{\text{max}}) = (1/T_{\text{max}}, 1/T_{\text{min}})$.  That is,
\[
\hat{f} = \arg\max_{f \in (f_{\text{min}}, f_{\text{max}})} I_y(f).
\] 
This is called the \emph{periodogram estimator}.  %This definition of the periodogram differs from the common definition in the spectral and frequency estimation literature~\cite{Hannan_time_series_1967,Quinn2001}.  
The statistical properties of the periodogram estimator were examined in~\cite{Quinn20013asilomar_period_est}.

The periodogram $I_y$ is not convex and has many local maxima.  In order to compute $\hat{f}$ it is usual to first compute $I_y$ on a grid of frequencies
\[
G = \{ f_{\text{min}} + Dk \mid k = 0, \dots K-1 \}
\]
where $D$ is the distance between frequencies in the grid, 
\[
K =  \floor{\frac{f_{\text{max}} - f_{\text{min}}}{D}}
\]
is the number of frequencies in the grid, and $\floor{\cdot}$ denotes the largest integer less than or equal to its argument.  
Let $\widetilde{f}$ be the maximiser of $I_y$ over $G$, that is, let
\[
\widetilde{f} = \arg\max_{f \in G} I_y(f).
\]
If the distance $D$ is sufficiently small, then $\widetilde{f}$ is a good approximation to the maximiser $\hat{f}$.  An iterative procedure, such as the Newton-Raphson method, or Brent's method~\cite[Ch.~5]{Brent_opt_no_derivs_1973} 
can then be used to compute $\hat{f}$ starting from $\widetilde{f}$.

\newcommand{\ymax}{y_{\text{max}}}
\newcommand{\ymin}{y_{\text{min}}}

In~\cite{McKilliam2007} it was observed that $D$ must shrink as $N$ increases in order for $\widetilde{f}$ to be a sufficiently good approximation to $\hat{f}$.  This was recently studied by Ye~et.~al.~\cite{Haohuan2013435,6492742} who heuristically suggest choosing
\begin{equation}\label{eq:gridwidthrecommended}
D = \frac{1}{2(\ymax - \ymin)}
\end{equation}
where $\ymax$ and $\ymin$ are the largest and smallest values from $y_1,\dots,y_N$.  This choice is supported by the simulations in~\cite{Haohuan2013435,6492742} and also those in Section~\ref{sec:simulations}.  With this choice $D = O(N^{-1})$ under reasonable assumptions about the integers $s_1,\dots,s_N$ and the noise $w_1,\dots,w_N$.  The asymptotic standard deviation of $\hat{f}$ is of order $O(N^{-3/2})$ as shown in~\cite{Quinn20013asilomar_period_est} and this initially suggests that $D = O(N^{-1})$ is too large.  However, the choice~\eqref{eq:gridwidthrecommended} does appear effective in practice.  A statistically rigorous justification for this choice of $D$ is beyond the scope of the present paper, but could potentially be developed using techniques like those in~\cite{Quinn2008maximizing_the_periodogram}.

With this choice for $D$ the number of elements in the grid grows linearly with $N$, that is, $K = O(N)$.  Computing $I_y(f)$ for each $f$ requires $O(N)$ operations and so computing $I_y(f)$ for all $f \in G$ requires $O(N^2)$ operations.  It follows that computation of $\widetilde{f}$ requires $O(N^2)$ operations and that the periodogram estimator $\hat{T} = 1/\hat{f}$ requires at least $O(N^2)$ operations to compute by this method.  %The choice for $D$ from~\eqref{eq:gridwidthrecommended} might not guarantee that application of a numerical optimisation proceedure, starting from $\widetilde{f}$, will result in $\hat{f}$.  For this reason, this approach can only be considered approximate.  However, the simulations presented in~\cite{Haohuan2013435,6492742} and those in Section~\ref{sec:simulations} suggest that~\eqref{eq:gridwidthrecommended} the approximation is very accurate.  
In the next section we describe a modification of the periodogram estimator.  The modification is such that the fast Fourier transform or the chirp z-transform~\cite{Rabiner1969} can be used to compute an approximation $\widetilde{f}^\prime$ to $\hat{f}$ with only $O(N\log N)$ operations.

\section{Quantization and the periodogram}\label{sec:quant-peri} 

Denote by $\round{x} = \sfloor{x + \tfrac{1}{2}}$ the nearest integer to $x$.  %The direction of rounding for half integers is not important.  Half integers are rounded up in our implementation.  
Let $q$ be a positive real number and define the quantization function
\[
Q(x) = \round{qx}/q
\]
that rounds its argument to a nearest multiple of $1/q$.  Large $q$ corresponds with fine quantization and small $q$ corresponds with coarse quantization.  Compute quantized observations
\[
z_n = Q(y_n) =  \ell_n/q, \qquad n = 1,\dots,N
\] 
where $\ell_n = \round{qy_n} \in \ints$.  The periodogram of the quantized observations $z_1,\dots,z_N$ is
\begin{align*}
I_z(f) = \babs{ \sum_{n=1}^N e^{ -2\pi j f z_n} }^2 = \babs{ \sum_{n=1}^N e^{ -2\pi j f \ell_n/q} }^2.
\end{align*}
Observe that $I_z$ is periodic with period $q$.  This indicates that quantization should be fine enough that 
\begin{equation}\label{eq:boundaliasingP}
q > f_{\text{max}} - f_{\text{min}}.
\end{equation}
Otherwise there would exist frequencies in the interval $(f_{\text{min}}, f_{\text{max}})$ that are aliases with respect to $I_z$.  %That is, there would exists two frequences $f_1,f_2 \in (f_{\text{min}}, f_{\text{max}})$ such that $f_1 = f_2 + 1/P$ and $I_z(f_1) = I_z(f_2)$.

Let $\widetilde{f}^\prime$ be the maximiser of $I_z$ over the grid $G$, that is,
\[
\widetilde{f}^\prime = \arg\max_{f \in G} I_z(f).
\]
If the quantization parameter $q$ is sufficiently large we expect that $I_z$ is close to $I_y$ and so $\widetilde{f}^\prime$ will be close to $\widetilde{f}$.  Thus, if $q$ is sufficiently large and the distance $D$ is sufficiently small we expect $\widetilde{f}^\prime$ to be a good approximation to $\hat{f}$.  An iterative procedure %or Brent's method~\cite{Brent_opt_no_derivs_1973} 
can then be used to compute $\hat{f}$ by maximising $I_y$ starting from $\widetilde{f}^\prime$.  

\newcommand{\ellmin}{\ell_{\text{min}}}
\newcommand{\ellmax}{\ell_{\text{max}}}

The maximiser $\widetilde{f}^\prime$ can be computed efficiently using the chirp z-transform.  Let $b_i$ be the number of integers from $\ell_1,\dots,\ell_N$ that are equal to $i$.  That is,
\[
b_i= \#\{ n \mid \ell_n = i, n = 1,\dots, N\}
\]
where $\#$ indicates the number of elements in a set.  Put $\ellmax = \round{q \ymax}$ and $\ellmin = \round{q \ymin}$ so that $b_i = 0$ if $i < \ellmin$ or $i > \ellmax$.  Now
\[
I_z(f) = \babs{ \sum_{i = \ellmin}^{\ellmax} e^{ -2\pi j f i/q} b_i }^2 = \babs{ \sum_{m = 0}^{\ellmax-\ellmin} e^{ -2\pi j f m/q} b_{m+\ellmin} }^2.
\]
We want to compute $I_z(f)$ for all $f$ in the grid $G$.  Putting
\[
v_m = e^{ -2\pi j f_{\text{min}}m/q} b_{m+\ellmin}
\]
we have
\[
I_z(f_{\text{min}} + Dk) = \babs{ \sum_{m = 0}^{\ellmax-\ellmin} e^{ -2\pi j Dk m/q} v_m }^2 = \abs{V_k}^2
\]   
where, using the notation of Rabiner~et.~al.~\cite[eq.~(10)]{Rabiner1969},
\[
V_k = \sum_{m = 0}^{\ellmax-\ellmin} e^{ -2\pi j Dk m/q} v_m = \sum_{m=0}^{\ellmax-\ellmin} A^{-m} W^{km} v_m,
\]
where $A = 1$, and $W = e^{ -2\pi j D/q}$.  All of $V_0,\dots,V_{K-1}$ can be efficiently computed by the chirp z-transform~\cite{Rabiner1969}.  Putting
\[
\hat{k} = \arg\max_{k = 0,1,\dots,K-1} \abs{ V_k }^2
\]
we have
\[ 
\widetilde{f}^\prime = f_{\text{min}} + D\hat{k} = \arg\max_{f \in G} I_z(f).
\]
%The frequency $\widetilde{f}^\prime$ can be used to initialize an iterative procedure to maximise $I_y$.  The procedure will converge to $\hat{f}$ if $\widetilde{f}^\prime$ is sufficiently close to $\hat{f}$.

An alternative to the chirp z-transform is to use a single fast Fourier transform.  We have found this to be faster than the chirp z-transform for all but exceptionally large $N$.  Suppose that we choose the distance $D$ and quantization parameter $q$ so that $M = q/D$ is an integer and
\[
M = \frac{q}{D} > \ellmax-\ellmin.
\]
With this choice
\[
I_z(f_{\text{min}} + Dk) = \sabs{\sum_{m = 0}^{M-1} e^{-2\pi j k m/M} v_m}^2 = \sabs{V_k}^2
\]
where $V_0,\dots,V_{M-1}$ are the Fourier coefficients of $v_0,\dots,v_{M-1}$ and can be computed using a fast Fourier transform of length $M$.  From inequality~\eqref{eq:boundaliasingP} we have
\[
M = \frac{q}{D} > \frac{f_{\text{max}} - f_{\text{min}}}{D} \geq \floor{\frac{f_{\text{max}} - f_{\text{min}}}{D}} = K
\]
and so, the required values  $V_0,\dots,V_{K-1}$ are the first $K$ Fourier coefficients.


\section{Computational complexity}\label{sec:comp-compl}

The previous section shows how $\widetilde{f}^\prime$ can be computed using either the chirp z-transform or a fast Fourier transform of length $M$.  We now describe recommended values for the parameters $q, M$, and $D$.  The simulations presented in Section~\ref{sec:simulations} suggest that an effective value for the quantization parameter is $q = 5 f_{\text{max}}$.  If the chirp z-transform is used then $D$ is chosen according to~\eqref{eq:gridwidthrecommended}.  The chirp z-transform requires computation of three fast Fourier transforms, each of length $L + K - 1$, where 
\[
L = \ellmax - \ellmin + 1 = \round{q\ymax} - \round{q\ymin} + 1.
\]
If instead a single fast Fourier transform is used then our recommended value for the length of the transform is $M= 2L$.  In this case the grid distance
\[ 
D = \frac{q}{M} = \frac{q}{2(\round{q\ymax} - \round{q\ymax} + 1)} \approx  \frac{1}{2(\ymax - \ymin)}
\]
is approximately equal to~\eqref{eq:gridwidthrecommended}.  

Observe that $L$ grows proportionally with $q$ and that $L = O(qN)$ under reasonable assumptions about the integers $s_1,\dots,s_N$ and the noise $w_1,\dots,w_N$.  %The most computationally expensive part of the chirp z-transform is the computation of three fast Fourier transforms of length $L+K-1$.  Alternatively, a single fast Fourier transform of length $M = 2L$ can be used.  
Thus, both chirp-z and fast Fourier transform methods require $O(qN\log(qN)) = O(N\log N)$ operations because $q$ does not depend on $N$.  However, it is apparent that the length of the transforms, and hence the complexity, increases as the quantization becomes finer, i.e., as $q$ increases.  This presents a trade off between computational complexity and quantization accuracy.  This trade off is investigated in Section~\ref{sec:simulations}.

Given the approximate maximiser $\widetilde{f}^\prime$ we apply the Newton-Raphson method to find a nearby stationary point of the periodogram $I_y$.  This proceeds by the iteration
\[
f_{n+1} = f_{n} - \frac{I_y^\prime(f_n)}{I_y^{\prime\prime}(f_n)}, \qquad f_{1} = \widetilde{f}^\prime
\]
where $I_y^\prime$ and $I_y^{\prime\prime}$ are the first and second derivative of $I_y$. This procedure converges to the maximiser $\hat{f}$ of $I_y$ provided that $\widetilde{f}^\prime$ is sufficiently close to $\hat{f}$.  In our implementation iterations are performed until $\sabs{f_{n+1}-f_n} < 10^{-10}$.  The number of iterations depends upon the distance $D$, but not on $N$.  Each iteration requires $O(N)$ operations and so the total number of operations required by the Newton-Raphson procedure has order $O(N)$.  In practice we find that the computational cost of the Newton-Raphson procedure is dominated by the cost of the chirp-z or fast Fourier transforms. 



\begin{figure}[t]
  \centering 
  \begin{tikzpicture}
    \selectcolormodel{gray} 
    \begin{axis}[font=\footnotesize,xmode=log,ymode=log,height=7cm,width=9cm,xlabel={$N$},ylabel={time (ms)},ylabel style={at={(0.08,0.41)}},xlabel style={at={(0.5,0.1)}}, legend style={draw=none,fill=none,legend pos=north west,cells={anchor=west},font=\footnotesize}]
      \addplot[mark=o,mark options={scale=1}] table {code/data/PeriodogramBenchmark};
      \addplot[mark=x,mark options={solid,fill=black,scale=1.3}] table {code/data/LeastSquaresBenchmark};
      \addplot[mark=*,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramq4.0Benchmark};
      \addplot[mark=triangle,mark options={solid,fill=black,scale=0.9}] table {code/data/QuantisedPeriodogramChirpZq4.0Benchmark};
      %\addplot[mark=square,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpBenchmark};
      \addplot[mark=square,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2newBenchmark};
      \legend{Periodogram, Least squares, Fast Fourier transform, Chirp z-transform, SLS2-new}
   \end{axis}
  \end{tikzpicture}  
  \caption{Computation time in milliseconds versus $N$ for the periodogram, least squares, and quantized periodogram estimators computed using the chirp z-transform and a single fast Fourier transform.}\label{plot:benchmark}
\end{figure} 


\begin{figure}[p] 
  \centering 
  \begin{tikzpicture} 
    \selectcolormodel{gray}
\begin{groupplot}[
    group style={ 
        group name=my plots,
        group size=1 by 4,
        %ylabels at=edge left,
        xlabels at=edge bottom,
        xticklabels at=edge bottom,
        vertical sep=0pt
    },
    ylabel style={at={(0.07,0.4)}},
    footnotesize,
    width=9.2cm,
    height=6.9cm,
    tickpos=left,
    ytick align=outside,
    xtick align=outside,
    xmode=log,
    ymode=log,
    enlarge x limits=false 
]

\nextgroupplot[
ylabel={MSE},
legend style={
  legend columns=2,
  draw=none,
  fill=none,
  %legend pos=north west,
  at={(0.75,1)},
  cells={anchor=west},
  font=\footnotesize,
},
ymin=2e-8
]

\addplot[mark=none,color=black] table {code/data/PeriodogramCLTN30geom1}; 
\addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN30geom1};
\addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q1.5geom1};
\addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN30q5.0geom1};
\addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN30geom1};
\addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.2}] table {code/data/NormalisedSamplingLLSN30geom1}; 
% \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN30geom1};
\addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN30geom1};

\legend{Perdg. theory, Least squares theory, $q=\tfrac{3}{2}f_{\text{max}}$, $q=5 f_{\text{max}}$, Periodogram, Least squares, SLS2-new}
\node[font=\footnotesize] at (axis cs:0.3,2e-8) [anchor=south east] {$\mu=1,N=30$};

\nextgroupplot[
ylabel={MSE},
ymin=2e-10
]
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN30geom10}; 
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN30geom10}; 
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q1.5geom10};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN30q5.0geom10};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1.1}] table {code/data/PeriodogramN30geom10};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1.3}] table {code/data/NormalisedSamplingLLSN30geom10}; 
  %     \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN30geom10};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN30geom10};
%      \addplot[mark=none,dashed,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q2};
 %     \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200};
 %     \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200}; 
 %     \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/PeriodogramN200};
 %     \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q3};
 %     \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q10};
%      \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/NormalisedSamplingLLSN200}; 
       \node[font=\footnotesize] at (axis cs:0.3,2e-10) [anchor=south east] {$\mu=10,N=30$};`

\nextgroupplot[
ylabel={MSE},
ymin=2e-13
]

\addplot[color=gray,mark=none,color=black] table {code/data/PeriodogramCLTN1200geom1}; 
\addplot[color=gray,mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN1200geom1};
\addplot[color=gray,mark=o,only marks,mark options={color=black,solid,fill=black,scale=1}] table {code/data/PeriodogramN1200geom1};
\addplot[color=gray,mark=x,only marks,mark options={color=black,solid,fill=black,scale=1.2}] table {code/data/NormalisedSamplingLLSN1200geom1};
% \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN1200geom1};
\addplot[color=gray,mark=square,only marks,mark options={solid,color=black,fill=black,scale=1}] table {code/data/SLS2newN1200geom1};
\addplot[color=gray,mark=triangle,only marks,mark options={solid,color=black,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q1.5geom1};
% \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q3};
\addplot[color=gray,mark=*,only marks,mark options={solid,color=black,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN1200q5.0geom1};
% \legend{Periodogram Theory, Least squares theory, Quantised periodogram, Periodogram, Least squares}
\node[font=\footnotesize] at (axis cs:0.3,2e-13) [anchor=south east] {$\mu=1,N=1200$};

\nextgroupplot[
xlabel={$\sigma^2$},
xlabel style={at={(0.5,0.1)}},
ylabel={MSE},
ymin=2e-15,
ymax=8e-1
%ytickten={-1,-3,-5,-7,-9,-11,-13}
]

     \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN1200geom10};
      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN1200geom10};
       \addplot[color=gray,mark=o,only marks,mark options={solid,color=black,fill=black,scale=1.1}] table {code/data/PeriodogramN1200geom10};
       \addplot[color=gray,mark=x,only marks,mark options={solid,color=black,fill=black,scale=1.3}] table {code/data/NormalisedSamplingLLSN1200geom10};
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN1100geom10};
       \addplot[color=gray,mark=square,only marks,mark options={solid,color=black,fill=black,scale=1}] table {code/data/SLS2newN1200geom10};
       \addplot[color=gray,mark=triangle,only marks,mark options={solid,color=black,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q1.5geom10};
      %\addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1100q3};
      \addplot[color=gray,mark=*,only marks,mark options={solid,color=black,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN1200q5.0geom10};
 %     \legend{Periodogram Theory, Least squares theory, Quantised periodogram, Periodogram, Least squares}
     %\legend{Periodogram theory, $q=\tfrac{3}{2}T_{\text{max}}$, $q=4T_{\text{max}}$, Periodogram, Least squares, SLS2-adj}
     \node[font=\footnotesize] at (axis cs:0.3,2e-15) [anchor=south east] {$\mu=10,N=1200$};
   %  \node[rotate=16,font=\footnotesize] at (axis cs:7e-4,1.5e-14) {$N=1200$}; 

\end{groupplot}

  \end{tikzpicture}  
  \caption{Mean square period error versus noise variance $\sigma^2$.  For each Monte-Carlo trial the integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed with mean $\mu$.}\label{plot:multipleN}
\end{figure} 


\section{Simulations} \label{sec:simulations}

This section presents the results of Monte-Carlo simulations with the periodogram estimator~\cite{Haohuan2013435,Fogel1989_bit_synch_zero_crossings}, the modified least squares estimator~\cite{Clarkson2007,McKilliam2007,Quinn_sparse_noisy_SSP_2012}, Clarkson's enhanced separable line search (SLS2-new) estimator~\cite{Clarkson2007,Sidiropoulos2005}, and the quantized periodogram estimator from Section~\ref{sec:quant-peri}.  The grid distance $D$ used for the periodogram and SLS2-new estimators is given by~\eqref{eq:gridwidthrecommended}.  The modified least squares estimator requires a smaller grid distance to work accurately and we choose~\eqref{eq:gridwidthrecommended} divided by three in our simulations.  %The quantized periodogram estimator is computed using a single fast Fourier transform of length $M = 2L = 2(\ellmax - \ellmin + 1)$.  
Both the periodogram and quanitised periodogram estimators use the Newton-Raphson method.  In all simulations the noise $w_1,\dots,w_N$ are independent and identically normally distributed with variance $\sigma^2$.  For each Monte-Carlo trial the integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=1,\dots,N-1$ are independent and identically geometrically distributed starting from zero with means $\mu=1$ and $10$.  The true period is $T_0 = \pi/3$, the true phase is $\theta_0 = 0.2$, and $T_{\text{min}} = 0.8$ and $T_{\text{max}} = 1.5$.

Figure~\ref{plot:multipleN} shows the mean square error of the estimators versus $\sigma^2$ for $N = 30$ and $N = 1200$.  In the left hand  plot $\mu=1$ and in the right hand plot $\mu=10$.  %Thus, on average $\tfrac{1}{3}$ of the elements of the point process~\eqref{eq:periodicprocess} are observed in the left hand  plot and only $\tfrac{1}{15}$ in the right hand plot.  
Three thousand Monte-Carlo trials are run for each value of $\sigma^2$.  The plots show the mean square error of the quantized periodogram estimator for two quantization parameters $q = \tfrac{3}{2}f_{\text{max}} = \tfrac{15}{8}$ and $q = 5 f_{\text{max}} = \tfrac{25}{4}$.  The estimator performs poorly when $q = \tfrac{3}{2}f_{\text{max}}$ (triangles) but performs almost identically to the original periodogram estimator (circles) when $q = 5 f_{\text{max}}$ (dots).  The plot also shows the mean square error of the modified least squares estimator~\cite{Clarkson2007,McKilliam2007} and the SLS2-new estimator~\cite{Clarkson2007,Sidiropoulos2005}.  %The statistical performance of the SLS2-new estimator is poor when compared with the other estimators.  %For small $\sigma^2$ the mean square error of the SLS2 estimator is almost three orders of magnitude less accurate when $N = 50$ and almost five orders of magnitude less accurate when $N=1000$.    
The solid line shows the mean square error of the periodogram estimator predicted by Theorem~2 from~\cite{Quinn20013asilomar_period_est}.  The dashed line shows the mean square error of the modified least squares estimator predicted by Theorem~3 from~\cite{Quinn_sparse_noisy_SSP_2012}.

Figure~\ref{plot:benchmark} shows the average running time for the estimators for $N$ in the range $10$ to $25000$ when $\mu=3$.  Running times for other values of $\mu$ lead to similar conclusions.  The quantization parameter is $q = 5 f_{\text{max}}$ so that the performance of the quantized periodogram estimator is similar to that of the original periodogram estimator as observed in Figure~\ref{plot:multipleN}.  The average running times for the quantized periodogram estimator computed using the chirp z-transform and using a single fast Fourier transform are shown.  The chirp z-transform is slower in these simulations, but is expected to be faster when $N$ is exceptionally large.  %The quantized periodogram estimator computed using a single fast Fourier transform is faster than the periodogram estimator when $N \geq 20$.  It is faster than the least squares estimator when $N \geq 80$ and it is faster than the SLS2-new estimator when $N \geq 400$.  
The quantized periodogram estimator is significantly faster than the other estimators for large $N$.  For example, when $N = 25000$ the periodogram estimator requires approximately 530 seconds, whereas the quantized periodogram estimator requires approximately 1 second.  The software is written in Java and the computer used is an Intel Core2 Q6600 running at \unit[2.4]{GHz}. 

 

\section{Conclusion}

We have considered the problem of estimating the period of a point process from $N$ observations that are both sparse and noisy.  By quantizing the observations we describe an estimator that can be computed in $O(N\log N)$ operations by use of the fast Fourier transform or chirp z-transform.  This improved upon existing accurate estimators that require at least $O(N^2)$ operations.  The trade off between computational complexity and quantization accuracy was examined by simulation.  The simulations indicate that significant computational savings are possible with negligible loss in statistical accuracy.

The new estimator has potential application to the synchronisation of communications devices~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings}, pulse repetition interval estimation in electronic support~\cite{EltonGray_puilse_train_rader_1994,Gray_more_pri_1994,Clarkson_thesis,clarkson_estimate_period_pulse_train_1996,Hauochan_pri_2012}, beat and tempo estimation in music~\cite{dixon_beat_extraction_2001}, spike interval estimation in neurology~\cite{Arnett_neuro_pri_1976,Brillinger_spike_trains_1988,Rossoni200630}, and in the analysis of internet traffic~\cite{He_detecting_periodic_patterns_in_internet_2006,5585849,5947313}.


\small
\bibliography{bib}


\end{document}


%%% Local Variables:
%%% TeX-source-correlate-mode: t
%%% mode: latex
%%% TeX-master: t
%%% End: 

