%\documentclass[a4paper,10pt]{article}
%\documentclass[draftcls, onecolumn, 11pt]{IEEEtran}
\documentclass[10pt,twocolumn,twoside]{IEEEtran}
%\documentclass[journal]{IEEEtran}
 
\usepackage{mathbf-abbrevs}
\input{defs}

\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{pgfplots}

%\usepackage{xr}
%\externaldocument{paper2}

\usepackage{amsmath,amsfonts,amssymb, amsthm, bm}

\usepackage[square,comma,numbers,sort&compress]{natbib}

\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\sinc}{\operatorname{sinc}}
\newcommand{\rect}[1]{\operatorname{rect}\left(#1\right)}

%opening
\title{Fast sparse period estimation}
\author{R.~G.~McKilliam, I.~V.~L.~Clarkson and B.~G.~Quinn    
\thanks{
R.~G.~McKilliam is with the Institute for Telecommunications Research, The University of South Australia, SA, 5095.  I.~V.~L.~Clarkson is with the School of Information Technology \& Electrical Engineering, The University of Queensland, QLD., 4072, Australia.  B.~G.~Quinn is with the Department of Statistics, Macquarie University, Sydney, NSW, 2109, Australia.
}}

\begin{document}

\maketitle

\begin{abstract}

The problem of estimating the period of a point process from observations that are both sparse and noisy is considered.  By sparse it is meant that only a potentially small unknown subset of the process is observed.  By noisy it is meant that the subset that is observed, is observed with some error, or noise.  Existing accurate algorithms for estimating the period require $O(N^2)$ operations where $N$ is the number of observations.  By quantising the observations we produce an estimator that requires only $O(N\log N)$ operations by use of the chirp z-transform or the fast Fourier transform.  The quantisation has the adverse affect of decreasing the accuracy of the estimator.  This is investigated by Monte-Carlo simulation.  The simulations indicate that significant computational savings are possible with negligible loss in statistical accuracy.

\end{abstract}
\begin{IEEEkeywords}
Period estimation, fast Fourier transform
\end{IEEEkeywords}

\section{Introduction}

Consider the periodic sequence of real numbers
\begin{equation}\label{eq:periodicprocess}
T_0 k + \theta_0, \qquad k \in \ints
\end{equation}
with period $T_0$ and phase $\theta_0$.  For example, the sequence might represent times at which the beat occurs in a musical score.  A problem of interest is to estimate $T_0$ and $\theta_0$ from $N$ observations $y_1,\dots,y_N$ of the form
\begin{equation} \label{eq:sigmodel}
y_n = T_0 s_n + \theta_0 + w_n, \qquad n = 1,\dots,N
\end{equation}
where $w_1,\dots,w_N$ represent noise and $s_1,\dots,s_N$ are unknown integers representing the subset of the periodic sequence that is observed.  The $y_1, \dots, y_N$ are \emph{sparse}, owing to the unknown integers $s_1,\dots,s_N$, and \emph{noisy}, owing to $w_1,\dots,w_N$, observations of the sequence~\eqref{eq:periodicprocess}.  For example, $y_1,\dots,y_N$ might represent times at which a bass drum hit is observed.  The drum hits might not occur at every beat and might occur off beat on some occasions.  Our aim in this case would be to estimate the beat of the music from the times of the drum hits.  The model is depicted in Figure~\ref{fig_stat_model}. %It is clear that any estimator of $T_0$ and $\theta_0$ must, either explicitly or implicitly, also produce and estimate of the unknow integers $s_1,\dots,s_N$ describing the subset of the periods that are observed.  

The problem of estimating $T_0$ is called the \emph{sparse, noisy period estimation problem}~\cite{Clarkson2007,McKilliam2007}.  Solutions have applications to synchronisation for telecommunications devices~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings,Sidiropoulos2005,5621928}, estimation of the pulse repetition interval in electronic support~\cite{EltonGray_puilse_train_rader_1994,Gray_more_pri_1994,Clarkson_thesis,clarkson_estimate_period_pulse_train_1996,Hauochan_pri_2012}, and beat and tempo estimation in music~\cite{dixon_beat_extraction_2001}.  The problem is closely related to spike interval estimation in neurology~\cite{Arnett_neuro_pri_1976,Brillinger_spike_trains_1988,Rossoni200630} and a similar model has been proposed for the detection of anomolies, such as denial-of-service attacks, in internet traffic~\cite{He_detecting_periodic_patterns_in_internet_2006,5585849,5947313}.  The problem is also connected with classical problems in number theory such as Diophantine approximation, lattice reduction, and the study of prime numbers~\cite{Cassels_geom_numbers_1997,490557,Clarkson_thesis,Lenstra1982,Wubben_2011,Casey1995,726812,CaseySadler_primes_2013}.

Least squares estimation of period has been studied in~\cite{Clarkson2007,McKilliam2007,Quinn_sparse_noisy_SSP_2012}.  The least squares estimator can be closely approximated using $O(N^2)$ operations by using special purpose algorithms from computational number theory~\cite{McKilliam2009CoxeterLattices,McKilliam2008,McKilliam2008b}.  The least squares estimator is also the maximum likelihood estimator in the case that the noise variables $w_1,\dots,w_N$ are independent and identically normally distributed.  An alternative estimator, called the~\emph{periodogram estimator}, was studied by Fogel and Gavish~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings} and involves the maximisation of Bartlett's periodogram for point processes~\cite{Bartlest_periodgram_point_process_1963}.  The statistical properties of the periodogram estimator were recently studied by Quinn~et.~al.~\cite{Quinn20013asilomar_period_est} who show the estimator to be strongly consistent and asymptotically normal under mild conditions on the noise $w_1,\dots,w_N$ and integers $s_1,\dots,s_N$.  The fastest existing algorithms can closely approximate the periodogram estimator in $O(N^2)$ operations.  We describe the periodogram estimator in Section~\ref{sec:peri-estim}.

In Section~\ref{sec:quant-peri} we show that, by quantising the observations $y_1,\dots,y_N$, an approximation to the periodogram estimator can be computed using only $O(N\log N)$ operations.  This is facilitated by either the chirp z-transform~\cite{Rabiner1969} or the fast Fourier transform.  The quantisation has the adverse affect of decreasing the accuracy of the estimator.  The estimator is accurate if a sufficiently fine quantiser is chosen, but this requires a larger transform.  The trade off between quantisation level, accuracy, and computational complexity is investigated by computer simulation in Section~\ref{sec:simulations}.  The simulations indicate that significant computational savings are possible with negligible loss in accuracy.  Sadler and Casey~\cite{726812} have previously suggested use of the fast Fourier transform for period estimation.  However, their estimator requires far larger transforms and produces less accurate results than the estimator described here (see Section~VI and Figures 1-4 in~\cite{726812}).  In contrast, our estimator has accuracy similar to the least squares estimator, i.e., similar to the maximum likelihood estimator if the noise variables $w_1,\dots,w_N$ are assumed independent and identically normally distributed.
 
{
\def\vertgap{2}
\def\ph{0.4}
\def\T{1.1}
\newcommand{\raxis}{\draw[->] (-0.25,0) -- (8,0) node[above] {$\reals$}; \draw (0,-0.06)-- node[below] {$0$} (0,0.06) }
\newcommand{\pulse}[1]{ \draw[->,>=latex] (#1,0) -- (#1,1) }
\newcommand{\pulsewithnode}[2]{ \draw[->,>=latex] (#1,0) -- node[right] {#2} (#1,1) }
\begin{figure}[t]
	\centering
\begin{tikzpicture}[font=\small]
    %\draw[very thin,color=gray] (-0.1,-1.1) grid (3.9,3.9);
\begin{scope}
    \raxis;
    \foreach \k in {0,1,...,6} { \k, \pulse{\T*\k+\ph}; }
    \draw[<->] (\T*2+\ph,1.2) -- node[above] {$T_0$} (\T*3+\ph,1.2) ;
    \draw[<->] (0.0,1.2) -- node[above] {$\theta_0$} (\ph,1.2) ; 
%    \draw[->] (-0.25,-2*\vertgap) -- (8,-2*\vertgap) node[above] {$\reals$};
\end{scope}
\begin{scope}[yshift=-\vertgap cm]
  \raxis;
  \node[below] at (\T*1+\ph-0.3,0) {$y_1$}; \pulsewithnode{\T*1+\ph-0.3}{$s_1=1$}; \draw[->] (\T*1+\ph,1.2) -- node[above] {$w_1$} (\T*1+\ph-0.3,1.2) ; 
  \node[below] at (\T*3+\ph+0.5,0) {$y_2$}; \pulsewithnode{\T*3+\ph+0.5}{$s_2=3$}; \draw[->] (\T*3+\ph,1.2) -- node[above] {$w_2$} (\T*3+\ph+0.5,1.2) ;
  \node[below] at (\T*6+\ph-0.4,0) {$y_3$}; \pulsewithnode{\T*6+\ph-0.4}{$s_3=6$};\draw[->] (\T*6+\ph,1.2) -- node[above] {$w_3$} (\T*6+\ph-0.4,1.2) ;
\end{scope}
\end{tikzpicture}
%		\includegraphics{figs/figures-1.mps}
		\caption{Sparse noisy observations of a periodic sequence.  The original sequence~\eqref{eq:periodicprocess} is shown on the top and sparse noisy observations according to~\eqref{eq:sigmodel} are shown on the bottom.  In this example the observed subset is represented by integers $s_1=1$, $s_2=3$ and $s_3=6$.}
		\label{fig_stat_model}
\end{figure}
}

\section{The periodogram estimator}\label{sec:peri-estim}

Before describing the periodogram estimator we state some required assumptions.  Observe that
\[
y_n = T_0 s_n + \theta_0 + w_n = \frac{T_0}{2} r_n + \theta_0 + w_n
\]
where $r_n = 2s_n \in \ints$.  Thus, to ensure identifiability, it is necessary to assume that $T_0$ lies in some interval $(T_{\text{min}}, T_{\text{max}})$ where $T_{\text{max}} < 2T_{\text{min}}$.  We also assume that $y_1,\dots,y_N$ are in ascending order.  This assumption can be made without loss of generality since it amounts only to sorting the observations if required.

%BLERG. $T_{\text{min}}, T_{\text{max}}$ identifiability and $y_1,\dots,y_N$ in accending order.

Fogel and Gavish~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings} proposed the estimator $\hat{T} = 1/\hat{f}$ where $\hat{f}$ is the maximiser of the~\emph{periodogram}
\[
I_y(f) = \babs{ \sum_{n=1}^N e^{ 2\pi j f y_n} }^2 = \babs{ \sum_{n=1}^N e^{ -2\pi j f y_n} }^2 
\]
over the interval $(f_{\text{min}}, f_{\text{max}}) = (1/T_{\text{max}}, 1/T_{\text{min}})$ and $j = \sqrt{-1}$.  That is,
\[
\hat{f} = \arg\max_{f \in (f_{\text{min}}, f_{\text{max}})} I_y(f).
\] 
This is called the \emph{periodogram estimator}.  This definition of the periodogram differs from the common definition in the spectral and frequency estimation literature~\cite{Hannan_time_series_1967,Quinn2001}.  The statistical properties of the periodogram estimator were examined in~\cite{Quinn20013asilomar_period_est}.

The periodogram $I_y$ is not convex and has many local maxima.  In order to compute $\hat{f}$ it is usual to first compute $I_y$ on a grid of frequencies
\[
G = \{ f_{\text{min}} + Dk \mid k = 0, \dots K-1 \},
\]
where $D$ is the distance between frequencies in the grid, 
\[
K =  \floor{\frac{f_{\text{max}} - f_{\text{min}}}{D}}
\]
is the number of frequencies in the grid, and $\floor{\cdot}$ denotes the largest integer less than or equal to its argument.  
Let $\widetilde{f}$ be the maximiser of $I_y$ over $G$, that is, let
\[
\widetilde{f} = \arg\max_{f \in G} I_y(f).
\]
If the distance $D$ is sufficiently small, then $\widetilde{f}$ is a good approximation to the maximiser $\hat{f}$.  An iterative procedure, such as the Newton-Raphson method, %, or Brent's method~\cite{Brent_opt_no_derivs_1973} 
can then be used to compute $\hat{f}$ starting from $\widetilde{f}$.

In~\cite{McKilliam2007} it was observed that $D$ must shrink as $N$ increases in order for $\widetilde{f}$ to be a sufficiently good approximation to $\hat{f}$.  This was recently studied by Ye~et.~al.~\cite{Haohuan2013435,6492742} who heuristically suggest choosing
\begin{equation}\label{eq:gridwidthrecommended}
D = \frac{1}{2(y_N - y_1)}
\end{equation}
which is $O(N^{-1})$ under reasonable assumptions about the integers $s_1,\dots,s_N$ and the noise $w_1,\dots,w_N$.  This choice is supported by the simulations in~\cite{Haohuan2013435,6492742} and also those in Section~\ref{sec:simulations}.  The asymptotic standard deviation of $\hat{f}$ is of order $O(N^{-3/2})$ as shown in~\cite{Quinn20013asilomar_period_est} and this initially suggests that $D = O(N^{-1})$ is too large.  However, the choice~\eqref{eq:gridwidthrecommended} does appear effective in practice.  A statistically rigorous justification for this choice of $D$ is beyond the scope of the present paper, but could potentially be developed using the techniques in~\cite{Quinn2008maximizing_the_periodogram}.

With this choice for $D$ the number of elements in the grid grows linearly with $N$, that is, $K = O(N)$.  Computing $I_y(f)$ for each $f$ requires $O(N)$ operations and so computing $I_y(f)$ for all $f \in G$ requires $O(N^2)$ operations.  It follows that computation of $\widetilde{f}$ requires $O(N^2)$ operations and that the periodogram estimator $\hat{T} = 1/\hat{f}$ requires at least $O(N^2)$ operations to compute by this method.  %The choice for $D$ from~\eqref{eq:gridwidthrecommended} might not guarantee that application of a numerical optimisation proceedure, starting from $\widetilde{f}$, will result in $\hat{f}$.  For this reason, this approach can only be considered approximate.  However, the simulations presented in~\cite{Haohuan2013435,6492742} and those in Section~\ref{sec:simulations} suggest that~\eqref{eq:gridwidthrecommended} the approximation is very accurate.  
In the next section we describe a modification of the periodogram estimator.  The modification is such that the fast Fourier transform or the chirp z-transform~\cite{Rabiner1969} can be used to compute an approximation $\widetilde{f}^\prime$ to $\hat{f}$ with only $O(N\log N)$ operations.

\section{Quantisation and the periodogram}\label{sec:quant-peri} 

Denote by $\round{x}$ the nearest integer to $x$.  The direction of rounding for half integers is not important.  Half integers are rounded up in our implementation.  Let $q$ be a real number and define the quantisation function
\[
Q(x) = \round{qx}/q
\]
that rounds its argument to a nearest multiple of $1/q$.  Large $q$ corresponds with fine quantisation and small $q$ corresponds with coarse quantisation.  Compute quantised observations
\[
z_n = Q(y_n) =  \ell_n/q, \qquad n = 1,\dots,N
\]
where $\ell_n = \round{qy_n} \in \ints$.  The periodogram of the quantised observations $z_1,\dots,z_N$ is
\begin{align*}
I_z(f) = \babs{ \sum_{n=1}^N e^{ -2\pi j f z_n} }^2 = \babs{ \sum_{n=1}^N e^{ -2\pi j f \ell_n/q} }^2.
\end{align*}
Let $\widetilde{f}^\prime$ be the maximiser of $I_z$ over the grid $G$, that is,
\[
\widetilde{f}^\prime = \arg\max_{f \in G} I_z(f).
\]
If the quantisation parameter $q$ is sufficiently large we expect that $I_z$ is close to $I_y$ and so $\widetilde{f}^\prime$ will be close to $\widetilde{f}$.  Thus, if $q$ is sufficiently large and the distance $D$ is sufficiently small we expect $\widetilde{f}^\prime$ to be a good approximation to $\hat{f}$.  An iterative procedure %or Brent's method~\cite{Brent_opt_no_derivs_1973} 
can then be used to compute $\hat{f}$ starting from $\widetilde{f}^\prime$.  
Observe that $I_z$ is periodic with period $q$.  This immediately indicates that we should choose the quantisation fine enough that 
\begin{equation}\label{eq:boundaliasingP}
q > f_{\text{max}} - f_{\text{min}}.
\end{equation}
Otherwise there would exist frequencies in the interval $(f_{\text{min}}, f_{\text{max}})$ that are aliases with respect to $I_z$.  %That is, there would exists two frequences $f_1,f_2 \in (f_{\text{min}}, f_{\text{max}})$ such that $f_1 = f_2 + 1/P$ and $I_z(f_1) = I_z(f_2)$.

The maximiser $\widetilde{f}^\prime$ can be computed efficiently using the chirp z-transform.  Let $b_i$ be the number of integers from $\ell_1,\dots,\ell_N$ that are equal to $i$.  That is,
\[
b_i= \#\{ n \mid \ell_n = i, n = 1,\dots, N\}
\]
where $\#$ indicates the number of elements in a set.  The integers $\ell_1,\dots,\ell_N$ are in ascending order because $y_1,\dots,y_N$ are in ascending order.  So $b_i = 0$ if $i < \ell_1$ or $i > \ell_N$.  Now
\[
I_z(f) = \babs{ \sum_{i = \ell_1}^{\ell_N} e^{ -2\pi j f i/q} b_i }^2 = \babs{ \sum_{m = 0}^{\ell_N-\ell_1} e^{ -2\pi j f m/q} b_{m+\ell_1} }^2.
\]
We want to compute $I_z(f)$ for all $f$ in the grid $G$.  Putting
\[
v_m = e^{ -2\pi j f_{\text{min}}m/q} b_{m+\ell_1}
\]
we have
\[
I_z(f_{\text{min}} + Dk) = \babs{ \sum_{m = 0}^{\ell_N-\ell_1} e^{ -2\pi j Dk m/q} v_m }^2 = \abs{V_k}^2
\]   
where, using the notation of Rabiner~et.~al.~\cite[eq.~(10)]{Rabiner1969},
\[
V_k = \sum_{m = 0}^{\ell_N-\ell_1} e^{ -2\pi j Dk m/q} v_m = \sum_{m=0}^{\ell_N-\ell_1} A^{-m} W^{km} v_m
\]
where $A = 1$ and $W = e^{ -2\pi j D/q}$.  All of $V_0,\dots,V_{K-1}$ can be efficiently computed by the chirp z-transform~\cite{Rabiner1969}.  Putting
\[
\hat{k} = \arg\max_{k = 0,1,\dots,K-1} \abs{ V_k }^2
\]
we have
\[ 
\widetilde{f}^\prime = f_{\text{min}} + D\hat{k} = \arg\max_{f \in G} I_z(f).
\]
The frequency $\widetilde{f}^\prime$ can be used to initialize an iterative procedure to maximise $I_y$.  The procedure will converge to $\hat{f}$ if $\widetilde{f}^\prime$ is sufficiently close to $\hat{f}$.

An alternative to the chirp z-transform is to use a single fast Fourier transform.  We have found this to be faster than the chirp z-transform for all but exceptionally large $N$.  Suppose that we choose the distance $D$ and quantisation parameter $q$ so that $M = q/D$ is an integer and
\[
M = \frac{q}{D} > \ell_N-\ell_1.
\]
With this choice
\[
I_z(f_{\text{min}} + Dk) = \sabs{\sum_{m = 0}^{M-1} e^{-2\pi j k m/M} v_m}^2 = \sabs{V_k}^2
\]
where $V_0,\dots,V_{M-1}$ are the Fourier coefficients of $v_0,\dots,v_{M-1}$ and can be computed using a fast Fourier transform of length $M$.  From inequality~\eqref{eq:boundaliasingP} we have
\[
M = \frac{q}{D} > \frac{f_{\text{max}} - f_{\text{min}}}{D} \geq \floor{\frac{f_{\text{max}} - f_{\text{min}}}{D}} = K
\]
and so, the required values  $V_0,\dots,V_{K-1}$ are the first $K$ Fourier coefficients.


\section{Computational complexity}\label{sec:comp-compl}

The previous section showed how $\widetilde{f}^\prime$ could be computed using either the chirp z-transform or a fast Fourier transform of length $M$.  We now describe recommended values for the parameters $q, M$, and $D$.  The simulations presented in Section~\ref{sec:simulations} suggest that a reasonable value for the quantisation parameter is $q = 4 f_{\text{max}}$.  If the chirp z-transform is used then $D$ is chosen according to~\eqref{eq:gridwidthrecommended}.  Computation of the chirp z-transform requires the computation of three fast Fourier transforms, each of length $L + K - 1$, where 
\[
L = \ell_N - \ell_1 + 1 = \round{qy_N} - \round{qy_1} + 1.
\]
If instead a single fast Fourier transform is used then our recommended value for the length of the transform is $M= 2L$.  In this case the grid distance
\[ 
D = \frac{q}{M} = \frac{q}{2(\round{qy_N} - \round{qy_1} + 1)} \approx  \frac{1}{2(y_N - y_1)}
\]
is approximately equal to~\eqref{eq:gridwidthrecommended}.  

Observe that $L$ grows proportionally with $q$ and, under reasonable assumptions about the integers $s_1,\dots,s_N$ and the noise variables $w_1,\dots,w_N$, we have $L = O(qN)$.  The most computationally expensive part of the chirp z-transform is the computation of three fast Fourier transforms of length $L+K-1$.  Alternatively, a single fast Fourier transform of length $M = 2L$ can be used.  Both approaches require $O(qN\log(qN)) = O(N\log N)$ operations because $q$ does not depend on $N$.  However, it is apparent that the length of the transforms, and hence the complexity, increases as the quantisation becomes finer, i.e., as $q$ increases.  This presents a trade off between computationally complexity and quantisation accuracy.  This trade off is investigated in the next section.


\begin{figure}[t]
  \centering 
  \begin{tikzpicture}
    \selectcolormodel{gray} 
    \begin{axis}[font=\footnotesize,xmode=log,ymode=log,height=7cm,width=9cm,xlabel={$N$},ylabel={time (ms)},ylabel style={at={(0.215,0.41)}},xlabel style={at={(0.5,0.205)}}, legend style={draw=none,fill=none,legend pos=north west,cells={anchor=west},font=\footnotesize}]
      \addplot[mark=o,mark options={scale=1}] table {code/data/PeriodogramBenchmark};
      \addplot[mark=x,mark options={solid,fill=black,scale=1}] table {code/data/LeastSquaresBenchmark};
      \addplot[mark=*,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramq4.0Benchmark};
      \addplot[mark=triangle,mark options={solid,fill=black,scale=0.9}] table {code/data/QuantisedPeriodogramChirpZq4.0Benchmark};
      %\addplot[mark=square,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpBenchmark};
      \addplot[mark=square,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2newBenchmark};
      \legend{Periodogram, Least squares, Fast Fourier transform, Chirp z-transform, SLS2-new}
   \end{axis}
  \end{tikzpicture}  
  \caption{Computation time in milliseconds versus $N$ for the periodogram, least squares, and quantised periodogram estimators computed using the chirp z-transform and a single fast Fourier transform.}\label{plot:benchmark}
\end{figure} 


\begin{figure*}[t] 
  \centering 
  \begin{tikzpicture} 
    \selectcolormodel{gray} 
    \begin{axis}[name=plot1,font=\footnotesize,xmode=log,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.19,0.28)}},xlabel style={at={(0.5,0.14)}}, legend style={at={(1.1,1.02)}, anchor=south,legend columns=6, cells={anchor=west,/tikz/every even column/.append style={column sep=0.2cm}}}]
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN30geom3}; 
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q1.5geom3};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN30q4.0geom3};
%      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN30};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN30geom3};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/NormalisedSamplingLLSN30geom3}; 
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN30geom3};
      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN30geom3};
%      \addplot[mark=none,dashed,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q2};
 %     \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200};
 %     \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200}; 
 %     \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/PeriodogramN200};
 %     \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q3};
 %     \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q10};
%      \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/NormalisedSamplingLLSN200};
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN1200geom3};
 %     \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN1200};
       \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN1200geom3};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/NormalisedSamplingLLSN1200geom3};
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN1200geom3};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN1200geom3};
       \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q1.5geom3};
      %\addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q3};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN1200q4.0geom3};
 %     \legend{Periodogram Theory, Least squares theory, Quantised periodogram, Periodogram, Least squares}
     \legend{Periodogram theory, $q=\tfrac{3}{2}f_{\text{max}}$, $q=4 f_{\text{max}}$, Periodogram, Least squares, SLS2-new}
     \node[rotate=15,font=\footnotesize] at (axis cs:6e-4,1e-8) {$N=30$};
     \node[rotate=15,font=\footnotesize] at (axis cs:7e-4,2e-13) {$N=1200$}; 
   \end{axis} 
 \begin{axis}[name=plot2,at={(11,0)},font=\footnotesize,xmode=log,ymode=log,height=10cm,width=9cm,xlabel={$\sigma^2$},ylabel={MSE},ylabel style={at={(0.19,0.28)}},xlabel style={at={(0.5,0.14)}}]
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN30geom15}; 
            \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q1.5geom15};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN30q4.0geom15};
%      \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN30};
      \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN30geom15};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/NormalisedSamplingLLSN30geom15}; 
  %     \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN30geom15};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN30geom15};
%      \addplot[mark=none,dashed,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN30q2};
 %     \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN200};
 %     \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN200}; 
 %     \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/PeriodogramN200};
 %     \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q3};
 %     \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN200q10};
%      \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/NormalisedSamplingLLSN200}; 
      \addplot[mark=none,color=black] table {code/data/PeriodogramCLTN1200geom15};
 %     \addplot[mark=none,color=black,dashed] table {code/data/NormalisedLLSCLTN1100};
       \addplot[mark=o,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/PeriodogramN1200geom15};
       \addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/NormalisedSamplingLLSN1200geom15};
 %      \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=0.8}] table {code/data/SLS2novlpN1100geom15};
       \addplot[mark=square,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/SLS2newN1200geom15};
       \addplot[mark=triangle,only marks,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1200q1.5geom15};
      %\addplot[mark=x,only marks,color=black,mark options={solid,fill=black,scale=1}] table {code/data/QuantisedPeriodogramFFTN1100q3};
      \addplot[mark=*,only marks,color=black,mark options={solid,fill=black,scale=0.5}] table {code/data/QuantisedPeriodogramFFTN1200q4.0geom15};
 %     \legend{Periodogram Theory, Least squares theory, Quantised periodogram, Periodogram, Least squares}
     %\legend{Periodogram theory, $q=\tfrac{3}{2}T_{\text{max}}$, $q=4T_{\text{max}}$, Periodogram, Least squares, SLS2-adj}
     \node[rotate=15,font=\footnotesize] at (axis cs:6e-4,4e-10) {$N=30$};
     \node[rotate=15,font=\footnotesize] at (axis cs:7e-4,0.6e-14) {$N=1200$}; 
   \end{axis}
  \end{tikzpicture}  
  \caption{Mean square period error versus noise variance $\sigma^2$.  The integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=2,\dots,N$ are independent and identically geometrically distributed with mean $\mu = 3$ in the plot on the left and mean $\mu=15$ in the plot on the right.}\label{plot:multipleN}
\end{figure*} 


\section{Simulations} \label{sec:simulations} 

This section presents the results of Monte-Carlo simulations with the periodogram estimator~\cite{Haohuan2013435,Fogel1989_bit_synch_zero_crossings}, the modified least squares estimator~\cite{Clarkson2007,McKilliam2007}, Clarkson's modification of the separable least squares line search (SLS2-new) estimator~\cite{Clarkson2007,Sidiropoulos2005}, and the quantised periodogram estimator from Section~\ref{sec:quant-peri}.  The grid distance $D$ used for the modified least squares, periodogram, and SLS2-new estimators is given by~\eqref{eq:gridwidthrecommended}.  The quantised periodogram estimator is computed using a single fast Fourier transform of length $M = 2L = 2(\ell_N - \ell_N + 1)$.  Both the periodogram and quanitised periodogram estimators use the Newton-Raphson method.  In all simulations the noise variables $w_1,\dots,w_N$ are independent and identically normally distributed with variance $\sigma^2$.  The integers $s_1,\dots,s_N$ are generated so that $s_1$ and $s_{n+1} - s_n$ for $n=2,\dots,N$ are independent and identically geometrically distributed starting from $1$ with means $\mu=3$ and $15$.  The true period is $T_0 = \pi/3$, the true phase is $\theta_0 = 0.2$, and $T_{\text{min}} = 0.8$ and $T_{\text{max}} = 1.5$.

Figure~\ref{plot:multipleN} shows the mean square error of the estimators versus $\sigma^2$ for $N = 30$ and $N = 1200$.  In the left hand  plot $\mu=3$ and in the right hand plot $\mu=15$.  Thus, on average $\tfrac{1}{3}$ of the elements of the point process~\eqref{eq:periodicprocess} are observed in the left hand  plot and only $\tfrac{1}{15}$ in the right hand plot.  Four thousand Monte-Carlo trials are run for each value of $\sigma^2$.  The plots show the mean square error of the quantised periodogram estimator for two quantisation parameters $q = \tfrac{3}{2}f_{\text{max}} = \tfrac{15}{8}$ and $q = 4 f_{\text{max}} = 5$.  The estimator performs poorly when $q = \tfrac{3}{2}f_{\text{max}}$ (triangles) but performs almost identically to the original periodogram estimator (circles) when $q = 4 f_{\text{max}}$ (dots).  For comparison purposes, the plot also shows the mean square error of the modified least squares estimator~\cite{Clarkson2007,McKilliam2007} and the SLS2-new estimator~\cite{Clarkson2007,Sidiropoulos2005}.  %The statistical performance of the SLS2-new estimator is poor when compared with the other estimators.  %For small $\sigma^2$ the mean square error of the SLS2 estimator is almost three orders of magnitude less accurate when $N = 50$ and almost five orders of magnitude less accurate when $N=1000$.   
The solid line shows the mean square error of the periodogram estimator predicted by Theorem~2 from~\cite{Quinn20013asilomar_period_est}.

Figure~\ref{plot:benchmark} shows the average running time for the estimators for $N$ in the range $10$ to $25000$ when $\mu=3$.  The running times when $\mu=15$ lead to similar conclusions and are omitted.  The quantisation parameter is $q = 4 f_{\text{max}}$ so that the performance of the quantised periodogram estimator is similar to that of the original periodogram estimator as observed in Figure~\ref{plot:multipleN}.  The average running times for the quantised periodogram estimator computed using the chirp z-transform and using a single fast Fourier transform are shown.  The chirp z-transform is slower in these simulations, but is expected to be faster when $N$ is exceptionally large.  The quantised periodogram estimator computed using a single fast Fourier transform is faster than the periodogram estimator when $N \geq 20$.  It is faster than the least squares estimator when $N \geq 80$ and it is faster than the SLS2-new estimator when $N \geq 400$.  The quantised periodogram estimator is significantly faster than the other estimator for large $N$.  For example, when $N = 25000$ the periodogram estimator requires approximately 530 seconds, whereas the quantised periodogram estimator requires approximately 960 milliseconds.  The software is written in Java and the computer used is an Intel Core2 Q6600 running at \unit[2.4]{GHz}. 

 

\section{Conclusion}

We have considered the problem of estimating the period of a point process from $N$ observations that are both sparse and noisy.  By quantising the observations we describe an estimator that can be computed in $O(N\log N)$ operations by use of the fast Fourier transform or chirp z-transform.  This is in contrast to existing accurate estimators that require at least $O(N^2)$ operations.  The trade off between computational complexity and quantisation accuracy was examined by simulation.  The simulations indicate that significant computational savings are possible with negligible loss in statistical accuracy.

The new estimator has potential application to the synchronisation of communications devices~\cite{Fogel1988,Fogel1989_bit_synch_zero_crossings}, pulse repetition interval estimation in electronic support~\cite{EltonGray_puilse_train_rader_1994,Gray_more_pri_1994,Clarkson_thesis,clarkson_estimate_period_pulse_train_1996,Hauochan_pri_2012}, beat and tempo estimation in music~\cite{dixon_beat_extraction_2001}, spike interval estimation in neurology~\cite{Arnett_neuro_pri_1976,Brillinger_spike_trains_1988,Rossoni200630}, and in the analysis of internet traffic~\cite{He_detecting_periodic_patterns_in_internet_2006,5585849,5947313}.


\small
\bibliography{bib}


\end{document}


%%% Local Variables:
%%% TeX-source-correlate-mode: t
%%% mode: latex
%%% TeX-master: t
%%% End: 

